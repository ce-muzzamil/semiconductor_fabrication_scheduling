{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13907d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r /kaggle/working\n",
    "# !git clone https://github.com/ce-muzzamil/semiconductor_fabrication_scheduling.git\n",
    "# !cp -v -r /kaggle/working/semiconductor_fabrication_scheduling/* /kaggle/working/\n",
    "# !rm -r /kaggle/working/semiconductor_fabrication_scheduling\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"/kaggle/working/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd20a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from simulation.file_instance import FileInstance\n",
    "from simulation.read import read_all\n",
    "from simulation.dispatching.dispatcher import dispatcher_map\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch.optim import Adam\n",
    "\n",
    "from logger import Logger\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f8c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCFabEnv:\n",
    "    def __init__(self, dataset, days=1, dispatcher='fifo', seed=0):\n",
    "        self.files = read_all('datasets/' + dataset)\n",
    "        self.instance = None\n",
    "        self.days = days\n",
    "        self.seed_val = seed\n",
    "        self.dispatcher = dispatcher_map[dispatcher]\n",
    "\n",
    "        self.none2zero = lambda x: 0.0 if x is None or x == '' else x \n",
    "\n",
    "    def reset(self, hard=True):\n",
    "        if not hard:\n",
    "            self.throughput = 0\n",
    "            self.tardiness = 0\n",
    "            return\n",
    "        \n",
    "        self.throughput = 0\n",
    "        self.tardiness = 0\n",
    "        run_to = 3600 * 24 * self.days\n",
    "        self.eid = np.random.randint(999_999_999)\n",
    "        self.instance = FileInstance(self.files, run_to, True, [])\n",
    "        self.num_lots_done = 0\n",
    "        self.lots_done = []\n",
    "        self.lots_dispatched = []\n",
    "        self.groups = {}\n",
    "        for machine in self.instance.machines:\n",
    "            if machine.group not in self.groups:\n",
    "                self.groups[machine.group] = set()\n",
    "            self.groups[machine.group].add(machine.family)\n",
    "\n",
    "        self.families = {}\n",
    "        for machine in self.instance.machines:\n",
    "            if machine.family not in self.families:\n",
    "                self.families[machine.family] = machine.group\n",
    "\n",
    "        self.loc_2_index = {k:e for e, k in enumerate(sorted(set([m.loc for m in self.instance.machines])))}\n",
    "        self.group_2_index = {k:e for e, k in enumerate(sorted(set(self.groups.keys())))}\n",
    "\n",
    "        self.instance.next_decision_point()\n",
    "        self.eid = np.random.randint(999_999_999)\n",
    "        machines = self.preprocess()\n",
    "        self.get_state(machines)\n",
    "        if len(self.conflicting_machines) > 0:\n",
    "            for family in self.conflicting_machines:\n",
    "                return self.state_tensor(family)\n",
    "        else:\n",
    "            return self.step(None)\n",
    "\n",
    "    @property\n",
    "    def get_machines_t(self):\n",
    "        \"\"\"usable machines at time t\"\"\"\n",
    "        machines = list(self.instance.usable_machines)\n",
    "        families = [m.family for m in machines]\n",
    "        machines = {family: {\"counts\": families.count(family), \"machines\":[machine for machine in machines if machine.family == family]} for family in families}\n",
    "\n",
    "        for family in machines:\n",
    "            step_names = set([lot.actual_step.step_name for lot in machines[family][\"machines\"][0].waiting_lots])\n",
    "            machines[family][\"lots_groups\"] = {step_name: [lot for lot in machines[family][\"machines\"][0].waiting_lots if lot.actual_step.step_name == step_name] for step_name in step_names}\n",
    "        \n",
    "        for family in machines:\n",
    "            if machines[family][\"counts\"] >= len(machines[family][\"lots_groups\"]):\n",
    "                machines[family][\"conflicting\"] = False\n",
    "            else:\n",
    "                machines[family][\"conflicting\"] = True\n",
    "        return machines\n",
    "    \n",
    "    def dispatch_non_conflicting(self, machines):\n",
    "        for family in machines:\n",
    "            if not machines[family][\"conflicting\"]:\n",
    "                for i, step_name in enumerate(machines[family][\"lots_groups\"]):\n",
    "                    self.instance.dispatch(machines[family][\"machines\"][i], machines[family][\"lots_groups\"][step_name])\n",
    "\n",
    "    def preprocess(self):\n",
    "        self.machines = self.get_machines_t\n",
    "        self.dispatch_non_conflicting(self.machines)\n",
    "        return self.machines\n",
    "    \n",
    "    def get_state(self, machines):\n",
    "        mask = {family:machines[family][\"conflicting\"] for family in machines}\n",
    "        conflicting_machines = {family:machines[family] for family in machines if mask[family]}\n",
    "        self.conflicting_machines = conflicting_machines\n",
    "        return conflicting_machines\n",
    "\n",
    "    def step(self, action):\n",
    "        families = self.conflicting_machines.keys()\n",
    "        for family in list(families):\n",
    "            if self.conflicting_machines[family][\"counts\"] == 0:\n",
    "                self.conflicting_machines.pop(family)\n",
    "\n",
    "        info = {\"time\": self.instance.current_time, \"done_lots\":[], \"dispatched_lots\": []}\n",
    "        new_lots_done = self.instance.done_lots[self.num_lots_done:]\n",
    "\n",
    "        for lot in new_lots_done:\n",
    "            if lot.idx in self.lots_dispatched:\n",
    "                self.lots_done.append(lot.idx)\n",
    "                info['done_lots'].append(lot)\n",
    "                self.throughput += 1\n",
    "                lateness_hours = 0 if lot.deadline_at >= lot.done_at else 1\n",
    "                self.tardiness += lateness_hours\n",
    "\n",
    "        self.num_lots_done = len(self.instance.done_lots)\n",
    "\n",
    "        if len(self.conflicting_machines) == 0:\n",
    "            machines = self.preprocess()\n",
    "            self.get_state(machines)\n",
    "            done = self.instance.next_decision_point()\n",
    "            if done or self.instance.current_time > 3600 * 24 * self.days:\n",
    "                done = True\n",
    "            for family in self.conflicting_machines:\n",
    "                return self.state_tensor(family), 0, done, info\n",
    "            \n",
    "        else:\n",
    "            families = self.conflicting_machines.keys()\n",
    "            for family in families:\n",
    "                if family in self.conflicting_machines.keys():\n",
    "                    lot_groups = self.conflicting_machines[family][\"lots_groups\"]\n",
    "\n",
    "                    for i, step_name in enumerate(lot_groups):\n",
    "                        if i == action:\n",
    "                            machine = self.conflicting_machines[family][\"machines\"].pop()\n",
    "                            lot_group = self.conflicting_machines[family][\"lots_groups\"].pop(step_name)\n",
    "                            self.conflicting_machines[family][\"counts\"] -= 1\n",
    "                            info[\"dispatched_lots\"].extend([lot.idx for lot in lot_group])\n",
    "                            self.lots_dispatched.extend([lot.idx for lot in lot_group])\n",
    "                            self.instance.dispatch(machine, lot_group)\n",
    "                            break\n",
    "                    break\n",
    "\n",
    "            for family in self.conflicting_machines:\n",
    "                if self.conflicting_machines[family][\"counts\"] > 0:\n",
    "                    return self.state_tensor(family), 0, False, info\n",
    "                \n",
    "        return None, 0, False, info\n",
    "                    \n",
    "    def state_tensor(self, family):\n",
    "        def foo(**kwargs):\n",
    "            return np.array(list(kwargs.values()))\n",
    "            \n",
    "        machine_features = foo(num_units=len(self.conflicting_machines[family][\"machines\"]),\n",
    "                               group_idx=self.group_2_index[self.families[family]],\n",
    "                               num_machine_families_in_group=len(self.groups[self.families[family]]),\n",
    "                               load_time_hr=np.mean([m.load_time for m in self.conflicting_machines[family][\"machines\"]])/3600,\n",
    "                               unload_time_hr=np.mean([m.unload_time for m in self.conflicting_machines[family][\"machines\"]])/3600,\n",
    "                               loc_idx=self.loc_2_index[self.conflicting_machines[family][\"machines\"][0].loc],\n",
    "                               num_waiting_lots=len(self.conflicting_machines[family][\"machines\"][0].waiting_lots),\n",
    "                               utilized_time=np.mean([m.utilized_time for m in self.conflicting_machines[family][\"machines\"]]),\n",
    "                               setuped_time=np.mean([m.setuped_time for m in self.conflicting_machines[family][\"machines\"]]),\n",
    "                               pmed_time=np.mean([m.pmed_time for m in self.conflicting_machines[family][\"machines\"]]),\n",
    "                               bred_time=np.mean([m.bred_time for m in self.conflicting_machines[family][\"machines\"]]),\n",
    "                               min_runs_left_max=np.max([self.none2zero(m.min_runs_left) for m in self.conflicting_machines[family][\"machines\"]]),\n",
    "                               min_runs_left_min=np.min([self.none2zero(m.min_runs_left) for m in self.conflicting_machines[family][\"machines\"]]))\n",
    "\n",
    "        lot_groups_features = []\n",
    "        for step_name in self.conflicting_machines[family][\"lots_groups\"]:\n",
    "            lot_group: list = self.conflicting_machines[family][\"lots_groups\"][step_name]\n",
    "            lot_group_features = [\n",
    "                len(lot_group),\n",
    "                np.mean([(lot.deadline_at - self.instance.current_time)/3600 for lot in lot_group]),\n",
    "                np.max([(lot.deadline_at - self.instance.current_time)/3600 for lot in lot_group]),\n",
    "                np.mean([(lot.relative_deadline)/3600 for lot in lot_group]),\n",
    "                np.max([(lot.relative_deadline)/3600 for lot in lot_group]),\n",
    "                np.mean([(self.instance.current_time - lot.free_since)/3600 for lot in lot_group]),\n",
    "                np.max([(self.instance.current_time - lot.free_since)/3600 for lot in lot_group]),\n",
    "                np.mean([len(lot.remaining_steps) for lot in lot_group]),\n",
    "                np.max([len(lot.remaining_steps) for lot in lot_group]),\n",
    "                np.mean([lot.cr(self.instance.current_time) for lot in lot_group]),\n",
    "                np.max([lot.cr(self.instance.current_time) for lot in lot_group]),\n",
    "                np.mean([lot.priority for lot in lot_group]),\n",
    "                np.max([lot.priority for lot in lot_group]),\n",
    "                lot_group[0].actual_step.processing_time.avg(),\n",
    "                lot_group[0].actual_step.batch_max,\n",
    "                lot_group[0].actual_step.batch_min,\n",
    "                0 if lot_group[0].actual_step.setup_needed == '' or lot_group[0].actual_step.setup_needed == self.conflicting_machines[family][\"machines\"][0].current_setup else 1\n",
    "            ]\n",
    "            lot_groups_features.append(np.concatenate([machine_features, np.array(lot_group_features)]))\n",
    "\n",
    "        return np.stack(lot_groups_features, axis=0).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb5567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnablePositionalEncoding(nn.Module):\n",
    "    def __init__(self, seq_len, d_model):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, seq_len, d_model))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_embedding[:, :x.shape[1], :]\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, seq_len, input_dim, num_layers=4, nhead=8, dim_feedforward=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.pos_encoder = LearnablePositionalEncoding(seq_len, input_dim)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        return x #N,L,E\n",
    "\n",
    "class EMB(nn.Module):\n",
    "    def __init__(self, embed_size, hdim, drp=0.1):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_size, hdim),\n",
    "            nn.Dropout(drp),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hdim, hdim),\n",
    "            nn.Dropout(drp),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hdim, embed_size),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        #N,L,E -> N,L,E\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, embed_size, hdim, drp=0.1):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_size, hdim),\n",
    "            nn.Dropout(drp),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hdim, hdim),\n",
    "            nn.Dropout(drp),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hdim, 1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        #N,L,E -> N,L,1\n",
    "        x = self.mlp(x)\n",
    "        return x.squeeze(-1)\n",
    "    \n",
    "class critic(nn.Module):\n",
    "    def __init__(self, embed_size, hdim, drp=0.1):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_size, hdim),\n",
    "            nn.Dropout(drp),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hdim, hdim),\n",
    "            nn.Dropout(drp),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hdim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #N,L,E -> N,1\n",
    "        x = self.mlp(x.mean(1))\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, embed_size, seq_len, num_enc, num_heads, hdim, drp=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Linear(input_dim, embed_size)\n",
    "        self.fe = EMB(embed_size, hdim, drp)\n",
    "        self.feature_extractor = FeatureExtractor(seq_len=seq_len, \n",
    "                                                  input_dim=embed_size, \n",
    "                                                  num_layers=num_enc, \n",
    "                                                  nhead=num_heads, \n",
    "                                                  dim_feedforward=hdim, \n",
    "                                                  dropout=drp)\n",
    "        self.actor = Actor(embed_size, hdim, drp)\n",
    "        self.critic = critic(embed_size, hdim, drp)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (N, L, E)\n",
    "        unsqueezed = False\n",
    "        if x.ndim == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "            unsqueezed = True\n",
    "            \n",
    "        x = self.embedding(x)\n",
    "        x_a = self.fe(x)\n",
    "        x_c = self.feature_extractor(x_a)  # (N, L, E)\n",
    "        logits, values = self.actor(x_c), self.critic(x_c)\n",
    "\n",
    "        if unsqueezed:\n",
    "            logits = logits.squeeze(0)\n",
    "            values = values.squeeze(0)\n",
    "\n",
    "        return logits, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85978e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_rollout(first_obs, env, model, *args, rollout_len=2048):\n",
    "    obs_buf, action_buf, reward_buf, done_buf, logp_buf, value_buf, info_buf, used_indices = args\n",
    "    last_used_indices = tuple(used_indices)\n",
    "    used_indices = []\n",
    "\n",
    "    obs = first_obs\n",
    "\n",
    "    counter = 0\n",
    "    while counter <= rollout_len:\n",
    "        store = False\n",
    "        if obs is not None:\n",
    "            with torch.no_grad():\n",
    "                logits, value = model(torch.from_numpy(obs))\n",
    "                \n",
    "            probs = F.softmax(logits, dim=0)\n",
    "            dist = Categorical(probs)\n",
    "            action = dist.sample()\n",
    "            store = True\n",
    "\n",
    "        next_obs, _, done, info = env.step(action if isinstance(action, int) else action.item())\n",
    "\n",
    "        if store:\n",
    "            action_buf.append(action)\n",
    "            logp_buf.append(dist.log_prob(action))\n",
    "            value_buf.append(value.squeeze(-1))\n",
    "            reward_buf.append(torch.tensor(0, dtype=torch.float32))\n",
    "        else:\n",
    "            action_buf.append(None)\n",
    "            logp_buf.append(None)\n",
    "            value_buf.append(None)\n",
    "            reward_buf.append(None)\n",
    "\n",
    "        obs_buf.append(obs)\n",
    "        done_buf.append(done)\n",
    "        info_buf.append(info)\n",
    "            \n",
    "        counter += len(info[\"done_lots\"])\n",
    "            \n",
    "        obs = next_obs\n",
    "        if done:\n",
    "            obs = None\n",
    "            break\n",
    "    \n",
    "    for i in range(len(info_buf)):\n",
    "        for lot in info_buf[i][\"done_lots\"]:\n",
    "            for j in range(i):\n",
    "                if j in last_used_indices:\n",
    "                    continue\n",
    "                if lot.idx in info_buf[j][\"dispatched_lots\"]:\n",
    "                    reward_buf[j] += (lot.deadline_at - lot.done_at)/3600\n",
    "                    used_indices.append(j)\n",
    "    \n",
    "    last_obs = obs\n",
    "    return obs_buf, action_buf, reward_buf, done_buf, logp_buf, value_buf, info_buf, used_indices, last_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_update(model, optimizer, obs_buf, action_buf, reward_buf, done_buf, logp_buf, value_buf,\n",
    "               gamma=0.95, lam=0.95, clip_ratio=0.2, epochs=1, batch_size=32):\n",
    "\n",
    "    returns = []\n",
    "    advs = []\n",
    "    gae = 0\n",
    "    last_value = 0\n",
    "\n",
    "    ploss, vloss = [], []\n",
    "    for t in reversed(range(len(reward_buf))):\n",
    "        mask = 1.0 - float(done_buf[t])\n",
    "        delta = reward_buf[t] + gamma * last_value * mask - value_buf[t]\n",
    "        gae = delta + gamma * lam * mask * gae\n",
    "        advs.insert(0, gae)\n",
    "        last_value = value_buf[t]\n",
    "        returns.insert(0, gae + value_buf[t])\n",
    "\n",
    "    advs = torch.tensor(advs, dtype=torch.float32, requires_grad=False)\n",
    "    returns = torch.tensor(returns, dtype=torch.float32, requires_grad=False)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for i in range(0, len(obs_buf), batch_size):\n",
    "            var = [model(torch.from_numpy(i)) for i in obs_buf[i:i+batch_size]]\n",
    "            logits, new_values = [i[0] for i in var], torch.tensor([i[1] for i in var])\n",
    "            dists = [Categorical(logits=l) for l in logits]\n",
    "\n",
    "            act_batch = action_buf[i:i+batch_size]\n",
    "            old_logp_batch = logp_buf[i:i+batch_size]\n",
    "\n",
    "            new_logp = []\n",
    "            for g in range(len(act_batch)):\n",
    "                dist = dists[g]\n",
    "                action = act_batch[g]\n",
    "                log_prob = dist.log_prob(action)\n",
    "                new_logp.append(log_prob)\n",
    "\n",
    "            ratio = [torch.exp(new_logp_i - old_logp_batch_i) for new_logp_i, old_logp_batch_i in zip(new_logp, old_logp_batch)]\n",
    "            adv_batch = advs[i:i+batch_size]\n",
    "            ret_batch = returns[i:i+batch_size]\n",
    "\n",
    "            surr1 = [r*a for r, a in zip(ratio, adv_batch)]\n",
    "            surr2 = [torch.clamp(r, 1.0-clip_ratio, 1.0+clip_ratio) * a for r, a in zip(ratio, adv_batch)]\n",
    "            policy_loss = -sum([min(s1, s2) for s1, s2 in zip(surr1, surr2)])/len(surr1)\n",
    "\n",
    "            value_loss = F.mse_loss(new_values.squeeze(-1), ret_batch)\n",
    "            loss = policy_loss + 0.25 * value_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ploss.append(policy_loss.item())\n",
    "            vloss.append(value_loss.item())\n",
    "    return np.mean(ploss), np.mean(vloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ec071",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SCFabEnv(days=90, \n",
    "               dataset=\"SMT2020_HVLM\", \n",
    "               dispatcher=\"fifo\", \n",
    "               seed=42)\n",
    "\n",
    "first_obs = env.reset()\n",
    "\n",
    "# model = Model(30, 128, 50, 4, 4, 256, 0.1)\n",
    "model = Model(30, 2, 50, 1, 1, 4, 0.0)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "(obs_buf, \n",
    " action_buf, \n",
    " reward_buf, \n",
    " done_buf, \n",
    " logp_buf, \n",
    " value_buf, \n",
    " info_buf,\n",
    " used_indices) = [], [], [], [], [], [], [], []\n",
    "\n",
    "logger = Logger(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b364e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(100):\n",
    "\n",
    "    if any(done_buf):\n",
    "        (obs_buf, \n",
    "         action_buf, \n",
    "         reward_buf, \n",
    "         done_buf, \n",
    "         logp_buf, \n",
    "         value_buf, \n",
    "         info_buf,\n",
    "         used_indices) = [], [], [], [], [], [], [], []\n",
    "\n",
    "    (obs_buf, \n",
    "    action_buf, \n",
    "    reward_buf, \n",
    "    done_buf, \n",
    "    logp_buf, \n",
    "    value_buf, \n",
    "    info_buf, \n",
    "    used_indices,\n",
    "    last_obs) = collect_rollout(first_obs, \n",
    "                                env, \n",
    "                                model, \n",
    "                                obs_buf, \n",
    "                                action_buf, \n",
    "                                reward_buf, \n",
    "                                done_buf, \n",
    "                                logp_buf, \n",
    "                                value_buf, \n",
    "                                info_buf,\n",
    "                                used_indices,\n",
    "                                rollout_len=10)\n",
    "\n",
    "    def filter_buf(*args, used_indices):\n",
    "        rets = []\n",
    "        for arg in args:\n",
    "            rets.append([i for e, i in enumerate(arg) if e in used_indices])\n",
    "        return rets\n",
    "\n",
    "    (obs_buf_ij, \n",
    "    action_buf_ij, \n",
    "    reward_buf_ij, \n",
    "    done_buf_ij, \n",
    "    logp_buf_ij, \n",
    "    value_buf_ij, \n",
    "    info_buf_ij) = filter_buf(obs_buf, \n",
    "                            action_buf, \n",
    "                            reward_buf, \n",
    "                            done_buf, \n",
    "                            logp_buf, \n",
    "                            value_buf, \n",
    "                            info_buf,\n",
    "                            used_indices=used_indices)\n",
    "\n",
    "    pl, vl = ppo_update(model, \n",
    "                        optimizer, \n",
    "                        obs_buf_ij, \n",
    "                        action_buf_ij, \n",
    "                        reward_buf_ij, \n",
    "                        done_buf_ij, \n",
    "                        logp_buf_ij, \n",
    "                        value_buf_ij,\n",
    "                        gamma=0.95, \n",
    "                        lam=0.95, \n",
    "                        clip_ratio=0.2, \n",
    "                        epochs=5, \n",
    "                        batch_size=5)\n",
    "    \n",
    "    logger.add_to_pool(eid=env.eid,\n",
    "                       reward=np.mean(reward_buf_ij),\n",
    "                       throughput=env.throughput,\n",
    "                       tardiness=env.tardiness,\n",
    "                       policy_loss=pl,\n",
    "                       value_loss=vl)\n",
    "    logger.commit()\n",
    "    env.reset(hard=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uw002",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
